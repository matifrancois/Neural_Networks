{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red Simple\n",
    "Con esta red se obtuvo un Accuracy en Test de 0.483. La red consta de 4 capas convolucionales con MaxPooling y 3 capas densas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-06-27T04:49:08.892652Z",
     "iopub.status.busy": "2021-06-27T04:49:08.892277Z",
     "iopub.status.idle": "2021-06-27T04:49:08.904229Z",
     "shell.execute_reply": "2021-06-27T04:49:08.903328Z",
     "shell.execute_reply.started": "2021-06-27T04:49:08.892612Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/rn2021q1itba-cifar100/submission_example.csv\n",
      "/kaggle/input/rn2021q1itba-cifar100/y_train.npy\n",
      "/kaggle/input/rn2021q1itba-cifar100/x_test.npy\n",
      "/kaggle/input/rn2021q1itba-cifar100/x_train.npy\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "import tensorflow.compat.v2 as tf\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow_datasets as tfds\n",
    "from keras import backend as K\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T04:49:08.906529Z",
     "iopub.status.busy": "2021-06-27T04:49:08.905937Z",
     "iopub.status.idle": "2021-06-27T04:49:09.003576Z",
     "shell.execute_reply": "2021-06-27T04:49:09.002716Z",
     "shell.execute_reply.started": "2021-06-27T04:49:08.906491Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train_val = np.load(\"/kaggle/input/rn2021q1itba-cifar100/x_train.npy\")\n",
    "x_test = np.load(\"/kaggle/input/rn2021q1itba-cifar100/x_test.npy\")\n",
    "y_train_val = np.load(\"/kaggle/input/rn2021q1itba-cifar100/y_train.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T04:49:09.005763Z",
     "iopub.status.busy": "2021-06-27T04:49:09.005420Z",
     "iopub.status.idle": "2021-06-27T04:49:09.131207Z",
     "shell.execute_reply": "2021-06-27T04:49:09.130295Z",
     "shell.execute_reply.started": "2021-06-27T04:49:09.005728Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "#Mostramos alguna imágen\n",
    "idx = 50\n",
    "plt.imshow(x_train_val[idx])\n",
    "plt.title(f'Clase: {y_train_val[idx]}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T04:49:09.133136Z",
     "iopub.status.busy": "2021-06-27T04:49:09.132787Z",
     "iopub.status.idle": "2021-06-27T04:49:09.858905Z",
     "shell.execute_reply": "2021-06-27T04:49:09.858059Z",
     "shell.execute_reply.started": "2021-06-27T04:49:09.133101Z"
    }
   },
   "outputs": [],
   "source": [
    "#Dividimos entre train y validación\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_val = x_train_val.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "     x_train_val, y_train_val, test_size=0.15, random_state=42, stratify=y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T04:49:09.860640Z",
     "iopub.status.busy": "2021-06-27T04:49:09.860243Z",
     "iopub.status.idle": "2021-06-27T04:49:09.870021Z",
     "shell.execute_reply": "2021-06-27T04:49:09.869149Z",
     "shell.execute_reply.started": "2021-06-27T04:49:09.860589Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 32, 32, 3)\n",
    "x_val = x_val.reshape(x_val.shape[0], 32, 32, 3)\n",
    "x_test = x_test.reshape(x_test.shape[0], 32, 32, 3)\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, 100)\n",
    "y_val = np_utils.to_categorical(y_val, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T04:49:09.871603Z",
     "iopub.status.busy": "2021-06-27T04:49:09.871244Z",
     "iopub.status.idle": "2021-06-27T04:49:09.879536Z",
     "shell.execute_reply": "2021-06-27T04:49:09.878699Z",
     "shell.execute_reply.started": "2021-06-27T04:49:09.871566Z"
    }
   },
   "outputs": [],
   "source": [
    "#Armamos la red de clasificación\n",
    "from tensorflow.keras.layers import Dense, Flatten, Activation, BatchNormalization, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback, TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers\n",
    "from keras.preprocessing.image import ImageDataGenerator  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T04:49:09.881201Z",
     "iopub.status.busy": "2021-06-27T04:49:09.880803Z",
     "iopub.status.idle": "2021-06-27T04:49:10.004990Z",
     "shell.execute_reply": "2021-06-27T04:49:10.004264Z",
     "shell.execute_reply.started": "2021-06-27T04:49:09.881166Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64,3, input_shape=(32,32,3)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(128,3))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(256,3))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(512,3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dense(100, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer= Adam(learning_rate=0.001), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=4, verbose=1, min_delta=1e-4) \n",
    "\n",
    "checkpoint_filepath = '/tmp/checkpoint3'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False,\n",
    "        rotation_range=0,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False)\n",
    "\n",
    "datagen.fit(x_train)\n",
    "\n",
    "it_train = datagen.flow(x_train, y_train, batch_size = 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T04:49:10.007379Z",
     "iopub.status.busy": "2021-06-27T04:49:10.007029Z",
     "iopub.status.idle": "2021-06-27T05:37:32.785380Z",
     "shell.execute_reply": "2021-06-27T05:37:32.784546Z",
     "shell.execute_reply.started": "2021-06-27T04:49:10.007344Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "664/664 [==============================] - 24s 35ms/step - loss: 4.1611 - accuracy: 0.0714 - val_loss: 3.6318 - val_accuracy: 0.1413\n",
      "Epoch 2/200\n",
      "664/664 [==============================] - 23s 34ms/step - loss: 3.5018 - accuracy: 0.1634 - val_loss: 3.2177 - val_accuracy: 0.2173\n",
      "Epoch 3/200\n",
      "664/664 [==============================] - 23s 35ms/step - loss: 3.1241 - accuracy: 0.2269 - val_loss: 3.4450 - val_accuracy: 0.2159\n",
      "Epoch 4/200\n",
      "664/664 [==============================] - 24s 36ms/step - loss: 2.8926 - accuracy: 0.2724 - val_loss: 3.0018 - val_accuracy: 0.2699\n",
      "Epoch 5/200\n",
      "664/664 [==============================] - 23s 34ms/step - loss: 2.7370 - accuracy: 0.3011 - val_loss: 2.7116 - val_accuracy: 0.3163\n",
      "Epoch 6/200\n",
      "664/664 [==============================] - 23s 34ms/step - loss: 2.6058 - accuracy: 0.3274 - val_loss: 2.6688 - val_accuracy: 0.3244\n",
      "Epoch 7/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 2.5169 - accuracy: 0.3461 - val_loss: 2.6289 - val_accuracy: 0.3376\n",
      "Epoch 8/200\n",
      "664/664 [==============================] - 21s 32ms/step - loss: 2.4381 - accuracy: 0.3624 - val_loss: 2.5852 - val_accuracy: 0.3523\n",
      "Epoch 9/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 2.3705 - accuracy: 0.3729 - val_loss: 2.6009 - val_accuracy: 0.3584\n",
      "Epoch 10/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 2.2909 - accuracy: 0.3917 - val_loss: 2.6330 - val_accuracy: 0.3465\n",
      "Epoch 11/200\n",
      "664/664 [==============================] - 21s 32ms/step - loss: 2.2492 - accuracy: 0.4034 - val_loss: 2.4763 - val_accuracy: 0.3748\n",
      "Epoch 12/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 2.1617 - accuracy: 0.4204 - val_loss: 2.6403 - val_accuracy: 0.3575\n",
      "Epoch 13/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 2.1587 - accuracy: 0.4188 - val_loss: 2.3566 - val_accuracy: 0.3945\n",
      "Epoch 14/200\n",
      "664/664 [==============================] - 21s 32ms/step - loss: 2.1142 - accuracy: 0.4324 - val_loss: 2.3205 - val_accuracy: 0.4077\n",
      "Epoch 15/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 2.0804 - accuracy: 0.4360 - val_loss: 2.4963 - val_accuracy: 0.3857\n",
      "Epoch 16/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 2.0153 - accuracy: 0.4538 - val_loss: 2.5596 - val_accuracy: 0.3696\n",
      "Epoch 17/200\n",
      "664/664 [==============================] - 21s 32ms/step - loss: 2.0141 - accuracy: 0.4532 - val_loss: 2.3312 - val_accuracy: 0.4088\n",
      "Epoch 18/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.9653 - accuracy: 0.4647 - val_loss: 2.4065 - val_accuracy: 0.3969\n",
      "Epoch 19/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.9428 - accuracy: 0.4674 - val_loss: 2.3315 - val_accuracy: 0.4137\n",
      "Epoch 20/200\n",
      "664/664 [==============================] - 22s 32ms/step - loss: 1.9126 - accuracy: 0.4790 - val_loss: 2.4046 - val_accuracy: 0.4052\n",
      "Epoch 21/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.8832 - accuracy: 0.4782 - val_loss: 2.3413 - val_accuracy: 0.4111\n",
      "Epoch 22/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.8680 - accuracy: 0.4877 - val_loss: 2.3515 - val_accuracy: 0.4093\n",
      "Epoch 23/200\n",
      "664/664 [==============================] - 21s 32ms/step - loss: 1.8494 - accuracy: 0.4836 - val_loss: 2.7973 - val_accuracy: 0.3424\n",
      "Epoch 24/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.8215 - accuracy: 0.4966 - val_loss: 2.4774 - val_accuracy: 0.4045\n",
      "Epoch 25/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.8009 - accuracy: 0.5017 - val_loss: 2.3540 - val_accuracy: 0.4155\n",
      "Epoch 26/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.7670 - accuracy: 0.5103 - val_loss: 2.4155 - val_accuracy: 0.4111\n",
      "Epoch 27/200\n",
      "664/664 [==============================] - 22s 34ms/step - loss: 1.7610 - accuracy: 0.5100 - val_loss: 2.4327 - val_accuracy: 0.4135\n",
      "Epoch 28/200\n",
      "664/664 [==============================] - 22s 34ms/step - loss: 1.7403 - accuracy: 0.5158 - val_loss: 2.3699 - val_accuracy: 0.4256\n",
      "Epoch 29/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.7133 - accuracy: 0.5221 - val_loss: 2.3800 - val_accuracy: 0.4191\n",
      "Epoch 30/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.7026 - accuracy: 0.5242 - val_loss: 2.3249 - val_accuracy: 0.4357\n",
      "Epoch 31/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.6949 - accuracy: 0.5235 - val_loss: 2.5061 - val_accuracy: 0.4061\n",
      "Epoch 32/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.6593 - accuracy: 0.5367 - val_loss: 2.3805 - val_accuracy: 0.4248\n",
      "Epoch 33/200\n",
      "664/664 [==============================] - 21s 32ms/step - loss: 1.6434 - accuracy: 0.5399 - val_loss: 2.3786 - val_accuracy: 0.4187\n",
      "Epoch 34/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.6420 - accuracy: 0.5378 - val_loss: 2.3606 - val_accuracy: 0.4324\n",
      "Epoch 35/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.6346 - accuracy: 0.5406 - val_loss: 2.4079 - val_accuracy: 0.4261\n",
      "Epoch 36/200\n",
      "664/664 [==============================] - 21s 32ms/step - loss: 1.6244 - accuracy: 0.5428 - val_loss: 2.3400 - val_accuracy: 0.4373\n",
      "Epoch 37/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.5941 - accuracy: 0.5463 - val_loss: 2.3979 - val_accuracy: 0.4175\n",
      "Epoch 38/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.5955 - accuracy: 0.5492 - val_loss: 2.3933 - val_accuracy: 0.4259\n",
      "Epoch 39/200\n",
      "664/664 [==============================] - 21s 32ms/step - loss: 1.5630 - accuracy: 0.5559 - val_loss: 2.3890 - val_accuracy: 0.4329\n",
      "Epoch 40/200\n",
      "664/664 [==============================] - 22s 34ms/step - loss: 1.5823 - accuracy: 0.5520 - val_loss: 2.3977 - val_accuracy: 0.4267\n",
      "Epoch 41/200\n",
      "664/664 [==============================] - 22s 34ms/step - loss: 1.5317 - accuracy: 0.5631 - val_loss: 2.5290 - val_accuracy: 0.4157\n",
      "Epoch 42/200\n",
      "664/664 [==============================] - 22s 34ms/step - loss: 1.5362 - accuracy: 0.5624 - val_loss: 2.4530 - val_accuracy: 0.4241\n",
      "Epoch 43/200\n",
      "664/664 [==============================] - 22s 34ms/step - loss: 1.5097 - accuracy: 0.5694 - val_loss: 2.3904 - val_accuracy: 0.4267\n",
      "Epoch 44/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.5242 - accuracy: 0.5677 - val_loss: 2.3689 - val_accuracy: 0.4340\n",
      "Epoch 45/200\n",
      "664/664 [==============================] - 22s 34ms/step - loss: 1.5037 - accuracy: 0.5738 - val_loss: 2.3813 - val_accuracy: 0.4319\n",
      "Epoch 46/200\n",
      "664/664 [==============================] - 22s 34ms/step - loss: 1.4792 - accuracy: 0.5732 - val_loss: 2.5098 - val_accuracy: 0.4127\n",
      "Epoch 47/200\n",
      "664/664 [==============================] - 23s 34ms/step - loss: 1.4870 - accuracy: 0.5788 - val_loss: 2.4020 - val_accuracy: 0.4416\n",
      "Epoch 48/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.4772 - accuracy: 0.5785 - val_loss: 2.4397 - val_accuracy: 0.4375\n",
      "Epoch 49/200\n",
      "664/664 [==============================] - 23s 35ms/step - loss: 1.4700 - accuracy: 0.5770 - val_loss: 2.7777 - val_accuracy: 0.3884\n",
      "Epoch 50/200\n",
      "664/664 [==============================] - 22s 34ms/step - loss: 1.4995 - accuracy: 0.5731 - val_loss: 2.3831 - val_accuracy: 0.4453\n",
      "Epoch 51/200\n",
      "664/664 [==============================] - 23s 34ms/step - loss: 1.4437 - accuracy: 0.5868 - val_loss: 2.4520 - val_accuracy: 0.4335\n",
      "Epoch 52/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.4325 - accuracy: 0.5893 - val_loss: 2.4362 - val_accuracy: 0.4413\n",
      "Epoch 53/200\n",
      "664/664 [==============================] - 23s 35ms/step - loss: 1.4176 - accuracy: 0.5927 - val_loss: 2.5947 - val_accuracy: 0.4169\n",
      "Epoch 54/200\n",
      "664/664 [==============================] - 22s 34ms/step - loss: 1.4144 - accuracy: 0.5909 - val_loss: 2.4528 - val_accuracy: 0.4412\n",
      "Epoch 55/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.4144 - accuracy: 0.5926 - val_loss: 2.4621 - val_accuracy: 0.4388\n",
      "Epoch 56/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.4053 - accuracy: 0.5964 - val_loss: 2.3966 - val_accuracy: 0.4493\n",
      "Epoch 57/200\n",
      "664/664 [==============================] - 22s 34ms/step - loss: 1.3939 - accuracy: 0.5985 - val_loss: 2.4773 - val_accuracy: 0.4460\n",
      "Epoch 58/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.3781 - accuracy: 0.6028 - val_loss: 2.4247 - val_accuracy: 0.4535\n",
      "Epoch 59/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.3725 - accuracy: 0.6030 - val_loss: 2.4785 - val_accuracy: 0.4445\n",
      "Epoch 60/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.3607 - accuracy: 0.6070 - val_loss: 2.4987 - val_accuracy: 0.4289\n",
      "Epoch 61/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.3551 - accuracy: 0.6086 - val_loss: 2.4013 - val_accuracy: 0.4499\n",
      "Epoch 62/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.3373 - accuracy: 0.6129 - val_loss: 2.6615 - val_accuracy: 0.4169\n",
      "Epoch 63/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.3527 - accuracy: 0.6091 - val_loss: 2.3993 - val_accuracy: 0.4541\n",
      "Epoch 64/200\n",
      "664/664 [==============================] - 21s 32ms/step - loss: 1.3308 - accuracy: 0.6149 - val_loss: 2.4531 - val_accuracy: 0.4471\n",
      "Epoch 65/200\n",
      "664/664 [==============================] - 22s 34ms/step - loss: 1.3288 - accuracy: 0.6150 - val_loss: 2.4993 - val_accuracy: 0.4401\n",
      "Epoch 66/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.3351 - accuracy: 0.6148 - val_loss: 2.5251 - val_accuracy: 0.4467\n",
      "Epoch 67/200\n",
      "664/664 [==============================] - 21s 32ms/step - loss: 1.3293 - accuracy: 0.6133 - val_loss: 2.4459 - val_accuracy: 0.4513\n",
      "Epoch 68/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.3132 - accuracy: 0.6183 - val_loss: 2.4290 - val_accuracy: 0.4535\n",
      "Epoch 69/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.3229 - accuracy: 0.6150 - val_loss: 2.4901 - val_accuracy: 0.4487\n",
      "Epoch 70/200\n",
      "664/664 [==============================] - 22s 32ms/step - loss: 1.2931 - accuracy: 0.6263 - val_loss: 2.4225 - val_accuracy: 0.4492\n",
      "Epoch 71/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.2910 - accuracy: 0.6214 - val_loss: 2.5156 - val_accuracy: 0.4328\n",
      "Epoch 72/200\n",
      "664/664 [==============================] - 22s 34ms/step - loss: 1.2800 - accuracy: 0.6261 - val_loss: 2.4035 - val_accuracy: 0.4493\n",
      "Epoch 73/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.3070 - accuracy: 0.6209 - val_loss: 2.6191 - val_accuracy: 0.4343\n",
      "Epoch 74/200\n",
      "664/664 [==============================] - 21s 32ms/step - loss: 1.2798 - accuracy: 0.6267 - val_loss: 2.4697 - val_accuracy: 0.4375\n",
      "Epoch 75/200\n",
      "664/664 [==============================] - 21s 32ms/step - loss: 1.2683 - accuracy: 0.6331 - val_loss: 2.4683 - val_accuracy: 0.4527\n",
      "Epoch 76/200\n",
      "664/664 [==============================] - 22s 34ms/step - loss: 1.2573 - accuracy: 0.6330 - val_loss: 2.4177 - val_accuracy: 0.4489\n",
      "Epoch 77/200\n",
      "664/664 [==============================] - 22s 34ms/step - loss: 1.2606 - accuracy: 0.6312 - val_loss: 2.4006 - val_accuracy: 0.4628\n",
      "Epoch 78/200\n",
      "664/664 [==============================] - 23s 34ms/step - loss: 1.2577 - accuracy: 0.6352 - val_loss: 2.5251 - val_accuracy: 0.4459\n",
      "Epoch 79/200\n",
      "664/664 [==============================] - 24s 36ms/step - loss: 1.2602 - accuracy: 0.6306 - val_loss: 2.5494 - val_accuracy: 0.4411\n",
      "Epoch 80/200\n",
      "664/664 [==============================] - 23s 34ms/step - loss: 1.2386 - accuracy: 0.6393 - val_loss: 2.5535 - val_accuracy: 0.4437\n",
      "Epoch 81/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.2509 - accuracy: 0.6319 - val_loss: 2.6258 - val_accuracy: 0.4361\n",
      "Epoch 82/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.2201 - accuracy: 0.6391 - val_loss: 2.4396 - val_accuracy: 0.4585\n",
      "Epoch 83/200\n",
      "664/664 [==============================] - 21s 32ms/step - loss: 1.2296 - accuracy: 0.6398 - val_loss: 2.5838 - val_accuracy: 0.4493\n",
      "Epoch 84/200\n",
      "664/664 [==============================] - 21s 32ms/step - loss: 1.2241 - accuracy: 0.6405 - val_loss: 2.4754 - val_accuracy: 0.4533\n",
      "Epoch 85/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.2252 - accuracy: 0.6377 - val_loss: 2.5984 - val_accuracy: 0.4419\n",
      "Epoch 86/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.1990 - accuracy: 0.6546 - val_loss: 2.4825 - val_accuracy: 0.4631\n",
      "Epoch 87/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.2061 - accuracy: 0.6433 - val_loss: 2.6133 - val_accuracy: 0.4420\n",
      "Epoch 88/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.2176 - accuracy: 0.6453 - val_loss: 2.5921 - val_accuracy: 0.4377\n",
      "Epoch 89/200\n",
      "664/664 [==============================] - 21s 32ms/step - loss: 1.2059 - accuracy: 0.6436 - val_loss: 2.5398 - val_accuracy: 0.4519\n",
      "Epoch 90/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 1.2136 - accuracy: 0.6448 - val_loss: 2.5569 - val_accuracy: 0.4439\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 91/200\n",
      "664/664 [==============================] - 22s 34ms/step - loss: 1.0896 - accuracy: 0.6762 - val_loss: 2.3711 - val_accuracy: 0.4784\n",
      "Epoch 92/200\n",
      "664/664 [==============================] - 21s 32ms/step - loss: 1.0157 - accuracy: 0.7000 - val_loss: 2.3725 - val_accuracy: 0.4861\n",
      "Epoch 93/200\n",
      "664/664 [==============================] - 22s 34ms/step - loss: 1.0011 - accuracy: 0.7052 - val_loss: 2.4021 - val_accuracy: 0.4801\n",
      "Epoch 94/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 0.9876 - accuracy: 0.7065 - val_loss: 2.4323 - val_accuracy: 0.4843\n",
      "Epoch 95/200\n",
      "664/664 [==============================] - 22s 32ms/step - loss: 0.9711 - accuracy: 0.7111 - val_loss: 2.4233 - val_accuracy: 0.4883\n",
      "Epoch 96/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 0.9698 - accuracy: 0.7137 - val_loss: 2.4320 - val_accuracy: 0.4868\n",
      "Epoch 97/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 0.9781 - accuracy: 0.7054 - val_loss: 2.4246 - val_accuracy: 0.4868\n",
      "Epoch 98/200\n",
      "664/664 [==============================] - 21s 32ms/step - loss: 0.9645 - accuracy: 0.7147 - val_loss: 2.4526 - val_accuracy: 0.4840\n",
      "Epoch 99/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 0.9649 - accuracy: 0.7148 - val_loss: 2.4353 - val_accuracy: 0.4879\n",
      "Epoch 100/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 0.9507 - accuracy: 0.7207 - val_loss: 2.4737 - val_accuracy: 0.4823\n",
      "Epoch 101/200\n",
      "664/664 [==============================] - 21s 32ms/step - loss: 0.9502 - accuracy: 0.7160 - val_loss: 2.4888 - val_accuracy: 0.4821\n",
      "Epoch 102/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 0.9397 - accuracy: 0.7197 - val_loss: 2.4946 - val_accuracy: 0.4825\n",
      "Epoch 103/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 0.9447 - accuracy: 0.7206 - val_loss: 2.4616 - val_accuracy: 0.4880\n",
      "Epoch 104/200\n",
      "664/664 [==============================] - 21s 32ms/step - loss: 0.9353 - accuracy: 0.7203 - val_loss: 2.4697 - val_accuracy: 0.4845\n",
      "Epoch 105/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 0.9399 - accuracy: 0.7199 - val_loss: 2.4944 - val_accuracy: 0.4821\n",
      "Epoch 106/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 0.9487 - accuracy: 0.7148 - val_loss: 2.4898 - val_accuracy: 0.4860\n",
      "Epoch 107/200\n",
      "664/664 [==============================] - 21s 32ms/step - loss: 0.9301 - accuracy: 0.7222 - val_loss: 2.4872 - val_accuracy: 0.4877\n",
      "Epoch 108/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 0.9177 - accuracy: 0.7295 - val_loss: 2.4998 - val_accuracy: 0.4888\n",
      "Epoch 109/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 0.9225 - accuracy: 0.7234 - val_loss: 2.4888 - val_accuracy: 0.4888\n",
      "Epoch 110/200\n",
      "664/664 [==============================] - 21s 32ms/step - loss: 0.9190 - accuracy: 0.7260 - val_loss: 2.4941 - val_accuracy: 0.4888\n",
      "Epoch 111/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 0.9467 - accuracy: 0.7169 - val_loss: 2.5156 - val_accuracy: 0.4852\n",
      "Epoch 112/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 0.9084 - accuracy: 0.7327 - val_loss: 2.5163 - val_accuracy: 0.4872\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 113/200\n",
      "664/664 [==============================] - 21s 32ms/step - loss: 0.9080 - accuracy: 0.7268 - val_loss: 2.5081 - val_accuracy: 0.4884\n",
      "Epoch 114/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 0.9009 - accuracy: 0.7320 - val_loss: 2.5092 - val_accuracy: 0.4891\n",
      "Epoch 115/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 0.9187 - accuracy: 0.7278 - val_loss: 2.5009 - val_accuracy: 0.4883\n",
      "Epoch 116/200\n",
      "664/664 [==============================] - 22s 32ms/step - loss: 0.9007 - accuracy: 0.7304 - val_loss: 2.5135 - val_accuracy: 0.4880\n",
      "Epoch 117/200\n",
      "664/664 [==============================] - 22s 34ms/step - loss: 0.8930 - accuracy: 0.7304 - val_loss: 2.5025 - val_accuracy: 0.4881\n",
      "Epoch 118/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 0.9178 - accuracy: 0.7250 - val_loss: 2.4978 - val_accuracy: 0.4896\n",
      "Epoch 119/200\n",
      "664/664 [==============================] - 21s 32ms/step - loss: 0.9048 - accuracy: 0.7305 - val_loss: 2.5065 - val_accuracy: 0.4880\n",
      "Epoch 120/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 0.9046 - accuracy: 0.7289 - val_loss: 2.4987 - val_accuracy: 0.4903\n",
      "Epoch 121/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 0.8873 - accuracy: 0.7353 - val_loss: 2.5129 - val_accuracy: 0.4881\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 122/200\n",
      "664/664 [==============================] - 21s 32ms/step - loss: 0.8899 - accuracy: 0.7334 - val_loss: 2.5088 - val_accuracy: 0.4877\n",
      "Epoch 123/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 0.8966 - accuracy: 0.7318 - val_loss: 2.5105 - val_accuracy: 0.4879\n",
      "Epoch 124/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 0.9003 - accuracy: 0.7298 - val_loss: 2.4998 - val_accuracy: 0.4897\n",
      "Epoch 125/200\n",
      "664/664 [==============================] - 21s 32ms/step - loss: 0.9150 - accuracy: 0.7276 - val_loss: 2.5077 - val_accuracy: 0.4887\n",
      "Epoch 126/200\n",
      "664/664 [==============================] - 22s 32ms/step - loss: 0.8801 - accuracy: 0.7344 - val_loss: 2.5079 - val_accuracy: 0.4887\n",
      "\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 127/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 0.8988 - accuracy: 0.7292 - val_loss: 2.5043 - val_accuracy: 0.4884\n",
      "Epoch 128/200\n",
      "664/664 [==============================] - 21s 32ms/step - loss: 0.8955 - accuracy: 0.7319 - val_loss: 2.5027 - val_accuracy: 0.4887\n",
      "Epoch 129/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 0.8908 - accuracy: 0.7302 - val_loss: 2.5069 - val_accuracy: 0.4892\n",
      "Epoch 130/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 0.8936 - accuracy: 0.7346 - val_loss: 2.5091 - val_accuracy: 0.4883\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 131/200\n",
      "664/664 [==============================] - 21s 32ms/step - loss: 0.8901 - accuracy: 0.7336 - val_loss: 2.5069 - val_accuracy: 0.4888\n",
      "Epoch 132/200\n",
      "664/664 [==============================] - 22s 33ms/step - loss: 0.9026 - accuracy: 0.7298 - val_loss: 2.5073 - val_accuracy: 0.4885\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 64)        1792      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               25700     \n",
      "=================================================================\n",
      "Total params: 1,777,636\n",
      "Trainable params: 1,775,716\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "steps = int(x_train.shape[0] / 64)\n",
    "model.fit(it_train,\n",
    "         validation_data=(x_val, y_val),\n",
    "         steps_per_epoch=steps, epochs=200, callbacks=[early_stop, reduce_lr, model_checkpoint_callback])\n",
    "\n",
    "model.load_weights(checkpoint_filepath)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T05:37:40.526711Z",
     "iopub.status.busy": "2021-06-27T05:37:40.526380Z",
     "iopub.status.idle": "2021-06-27T05:37:41.134898Z",
     "shell.execute_reply": "2021-06-27T05:37:41.133963Z",
     "shell.execute_reply.started": "2021-06-27T05:37:40.526680Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test = model.predict(x_test).argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T05:37:43.289117Z",
     "iopub.status.busy": "2021-06-27T05:37:43.288794Z",
     "iopub.status.idle": "2021-06-27T05:37:43.294049Z",
     "shell.execute_reply": "2021-06-27T05:37:43.293149Z",
     "shell.execute_reply.started": "2021-06-27T05:37:43.289087Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([90, 33, 56, ..., 51, 42, 70])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T05:37:54.989993Z",
     "iopub.status.busy": "2021-06-27T05:37:54.989679Z",
     "iopub.status.idle": "2021-06-27T05:37:55.017673Z",
     "shell.execute_reply": "2021-06-27T05:37:55.016905Z",
     "shell.execute_reply.started": "2021-06-27T05:37:54.989964Z"
    }
   },
   "outputs": [],
   "source": [
    "#Salvo las predicciones y genero el archivo csv según el formato pedido\n",
    "df = pd.DataFrame(y_test, columns=[\"label\"])\n",
    "df.index.name = \"Id\"\n",
    "df.to_csv(\"submission4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T05:37:59.063911Z",
     "iopub.status.busy": "2021-06-27T05:37:59.063588Z",
     "iopub.status.idle": "2021-06-27T05:37:59.071149Z",
     "shell.execute_reply": "2021-06-27T05:37:59.070240Z",
     "shell.execute_reply.started": "2021-06-27T05:37:59.063874Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label\n",
       "Id       \n",
       "0      90\n",
       "1      33\n",
       "2      56\n",
       "3      51\n",
       "4      71"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
