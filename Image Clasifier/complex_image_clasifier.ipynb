{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red Compleja\n",
    "Con esta red se obtuvo un Accuracy en Test de 0.629. La red consta de 12 capas convolucionales con MaxPooling y 2 capas densas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-06-27T14:41:21.334643Z",
     "iopub.status.busy": "2021-06-27T14:41:21.334295Z",
     "iopub.status.idle": "2021-06-27T14:41:21.344594Z",
     "shell.execute_reply": "2021-06-27T14:41:21.343448Z",
     "shell.execute_reply.started": "2021-06-27T14:41:21.334608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/rn2021q1itba-cifar100/submission_example.csv\n",
      "/kaggle/input/rn2021q1itba-cifar100/y_train.npy\n",
      "/kaggle/input/rn2021q1itba-cifar100/x_test.npy\n",
      "/kaggle/input/rn2021q1itba-cifar100/x_train.npy\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "import tensorflow.compat.v2 as tf\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow_datasets as tfds\n",
    "from keras import backend as K\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T14:41:21.350747Z",
     "iopub.status.busy": "2021-06-27T14:41:21.350102Z",
     "iopub.status.idle": "2021-06-27T14:41:21.431910Z",
     "shell.execute_reply": "2021-06-27T14:41:21.431044Z",
     "shell.execute_reply.started": "2021-06-27T14:41:21.350710Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train_val = np.load(\"/kaggle/input/rn2021q1itba-cifar100/x_train.npy\")\n",
    "x_test = np.load(\"/kaggle/input/rn2021q1itba-cifar100/x_test.npy\")\n",
    "y_train_val = np.load(\"/kaggle/input/rn2021q1itba-cifar100/y_train.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T14:41:21.436572Z",
     "iopub.status.busy": "2021-06-27T14:41:21.436301Z",
     "iopub.status.idle": "2021-06-27T14:41:21.568573Z",
     "shell.execute_reply": "2021-06-27T14:41:21.567628Z",
     "shell.execute_reply.started": "2021-06-27T14:41:21.436543Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "#Mostramos alguna imágen\n",
    "idx = 50\n",
    "plt.imshow(x_train_val[idx])\n",
    "plt.title(f'Clase: {y_train_val[idx]}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T14:41:21.570813Z",
     "iopub.status.busy": "2021-06-27T14:41:21.570455Z",
     "iopub.status.idle": "2021-06-27T14:41:22.287034Z",
     "shell.execute_reply": "2021-06-27T14:41:22.286167Z",
     "shell.execute_reply.started": "2021-06-27T14:41:21.570777Z"
    }
   },
   "outputs": [],
   "source": [
    "#Dividimos entre train y validación\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train_val = x_train_val.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "     x_train_val, y_train_val, test_size=0.15, random_state=42, stratify=y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T14:41:22.288927Z",
     "iopub.status.busy": "2021-06-27T14:41:22.288576Z",
     "iopub.status.idle": "2021-06-27T14:41:22.298923Z",
     "shell.execute_reply": "2021-06-27T14:41:22.297886Z",
     "shell.execute_reply.started": "2021-06-27T14:41:22.288891Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 32, 32, 3)\n",
    "x_val = x_val.reshape(x_val.shape[0], 32, 32, 3)\n",
    "x_test = x_test.reshape(x_test.shape[0], 32, 32, 3)\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, 100)\n",
    "y_val = np_utils.to_categorical(y_val, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T14:41:22.300957Z",
     "iopub.status.busy": "2021-06-27T14:41:22.300585Z",
     "iopub.status.idle": "2021-06-27T14:41:22.308954Z",
     "shell.execute_reply": "2021-06-27T14:41:22.307862Z",
     "shell.execute_reply.started": "2021-06-27T14:41:22.300902Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten, Activation, BatchNormalization, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback, TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam, Nadam, SGD\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "from tensorflow.keras import activations\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from tensorflow.keras import layers\n",
    "from keras.preprocessing.image import ImageDataGenerator  \n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parámetros\n",
    "num_classes = 100\n",
    "weight_decay = 0.0005\n",
    "x_shape = [32,32,3]\n",
    "batch_size = 128\n",
    "maxepoches = 130\n",
    "learning_rate = 0.1\n",
    "lr_decay = 1e-6\n",
    "lr_drop = 20\n",
    "\n",
    "def add_layer(model, convSize, dropOut = -1, maxPooling = False):\n",
    "    model.add(Conv2D(convSize, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    if (dropOut != -1):\n",
    "        model.add(Dropout(dropOut))\n",
    "    if (maxPooling):\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                 input_shape=[32,32,3],kernel_regularizer=regularizers.l2(0.0005)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "add_layer(model, 64, maxPooling = True)\n",
    "add_layer(model, 128, dropOut = 0.4)\n",
    "add_layer(model, 128, maxPooling = True)\n",
    "add_layer(model, 256, dropOut = 0.4)\n",
    "add_layer(model, 256, dropOut = 0.4)\n",
    "add_layer(model, 256, maxPooling = True)\n",
    "add_layer(model, 512, dropOut = 0.4)\n",
    "add_layer(model, 512, dropOut = 0.4)\n",
    "add_layer(model, 512, maxPooling = True)\n",
    "add_layer(model, 512, dropOut = 0.4)\n",
    "add_layer(model, 512, dropOut = 0.4)\n",
    "add_layer(model, 512, maxPooling = True)\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,kernel_regularizer=regularizers.l2(0.0005)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_scheduler(epoch):\n",
    "    return learning_rate * (0.5 ** (epoch // lr_drop))\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15, \n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    "    horizontal_flip=True) \n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T14:41:24.204170Z",
     "iopub.status.busy": "2021-06-27T14:41:24.203816Z",
     "iopub.status.idle": "2021-06-27T19:21:13.753046Z",
     "shell.execute_reply": "2021-06-27T19:21:13.752275Z",
     "shell.execute_reply.started": "2021-06-27T14:41:24.204116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/130\n",
      "332/332 [==============================] - 132s 392ms/step - loss: 23.4600 - accuracy: 0.0173 - val_loss: 18.0720 - val_accuracy: 0.0109\n",
      "Epoch 2/130\n",
      "332/332 [==============================] - 129s 388ms/step - loss: 15.5240 - accuracy: 0.0423 - val_loss: 11.3738 - val_accuracy: 0.0237\n",
      "Epoch 3/130\n",
      "332/332 [==============================] - 129s 388ms/step - loss: 9.9447 - accuracy: 0.0531 - val_loss: 8.4537 - val_accuracy: 0.0263\n",
      "Epoch 4/130\n",
      "332/332 [==============================] - 129s 388ms/step - loss: 7.0876 - accuracy: 0.0706 - val_loss: 6.3503 - val_accuracy: 0.0425\n",
      "Epoch 5/130\n",
      "332/332 [==============================] - 129s 388ms/step - loss: 5.8666 - accuracy: 0.0650 - val_loss: 5.7970 - val_accuracy: 0.0515\n",
      "Epoch 6/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 5.0000 - accuracy: 0.0869 - val_loss: 5.3633 - val_accuracy: 0.0487\n",
      "Epoch 7/130\n",
      "332/332 [==============================] - 129s 388ms/step - loss: 4.5174 - accuracy: 0.0998 - val_loss: 4.3543 - val_accuracy: 0.1039\n",
      "Epoch 8/130\n",
      "332/332 [==============================] - 129s 388ms/step - loss: 4.2839 - accuracy: 0.1128 - val_loss: 4.1867 - val_accuracy: 0.1095\n",
      "Epoch 9/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 4.0982 - accuracy: 0.1268 - val_loss: 4.8543 - val_accuracy: 0.0848\n",
      "Epoch 10/130\n",
      "332/332 [==============================] - 129s 388ms/step - loss: 4.0469 - accuracy: 0.1402 - val_loss: 13.2622 - val_accuracy: 0.0125\n",
      "Epoch 11/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 4.1461 - accuracy: 0.1433 - val_loss: 6.9858 - val_accuracy: 0.0437\n",
      "Epoch 12/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 4.1979 - accuracy: 0.1500 - val_loss: 7.0862 - val_accuracy: 0.0416\n",
      "Epoch 13/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 4.0775 - accuracy: 0.1778 - val_loss: 6.1836 - val_accuracy: 0.0399\n",
      "Epoch 14/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 4.2071 - accuracy: 0.1807 - val_loss: 4.4429 - val_accuracy: 0.1608\n",
      "Epoch 15/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 4.0449 - accuracy: 0.2053 - val_loss: 3.9453 - val_accuracy: 0.2317\n",
      "Epoch 16/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.9672 - accuracy: 0.2284 - val_loss: 3.7948 - val_accuracy: 0.2472\n",
      "Epoch 17/130\n",
      "332/332 [==============================] - 129s 388ms/step - loss: 3.8309 - accuracy: 0.2480 - val_loss: 4.1905 - val_accuracy: 0.2087\n",
      "Epoch 18/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.9134 - accuracy: 0.2512 - val_loss: 4.0942 - val_accuracy: 0.2481\n",
      "Epoch 19/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.8342 - accuracy: 0.2647 - val_loss: 4.2388 - val_accuracy: 0.2363\n",
      "Epoch 20/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.8271 - accuracy: 0.2806 - val_loss: 7.4089 - val_accuracy: 0.0345\n",
      "Epoch 21/130\n",
      "332/332 [==============================] - 129s 388ms/step - loss: 4.1584 - accuracy: 0.2483 - val_loss: 3.6332 - val_accuracy: 0.3353\n",
      "Epoch 22/130\n",
      "332/332 [==============================] - 129s 388ms/step - loss: 3.6240 - accuracy: 0.3216 - val_loss: 3.3996 - val_accuracy: 0.3563\n",
      "Epoch 23/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.4315 - accuracy: 0.3450 - val_loss: 3.4399 - val_accuracy: 0.3532\n",
      "Epoch 24/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.4113 - accuracy: 0.3448 - val_loss: 3.6472 - val_accuracy: 0.3287\n",
      "Epoch 25/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.4369 - accuracy: 0.3501 - val_loss: 4.0880 - val_accuracy: 0.2503\n",
      "Epoch 26/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.5279 - accuracy: 0.3490 - val_loss: 20.6909 - val_accuracy: 0.0137\n",
      "Epoch 27/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 4.2255 - accuracy: 0.2606 - val_loss: 3.8521 - val_accuracy: 0.3233\n",
      "Epoch 28/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.6649 - accuracy: 0.3460 - val_loss: 3.7614 - val_accuracy: 0.3291\n",
      "Epoch 29/130\n",
      "332/332 [==============================] - 129s 388ms/step - loss: 3.4998 - accuracy: 0.3746 - val_loss: 3.3689 - val_accuracy: 0.3944\n",
      "Epoch 30/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.4738 - accuracy: 0.3737 - val_loss: 3.6253 - val_accuracy: 0.3581\n",
      "Epoch 31/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.5084 - accuracy: 0.3702 - val_loss: 3.3691 - val_accuracy: 0.4021\n",
      "Epoch 32/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.4164 - accuracy: 0.3926 - val_loss: 3.6250 - val_accuracy: 0.3836\n",
      "Epoch 33/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.7391 - accuracy: 0.3530 - val_loss: 3.8305 - val_accuracy: 0.3596\n",
      "Epoch 34/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.7841 - accuracy: 0.3643 - val_loss: 3.6155 - val_accuracy: 0.3811\n",
      "Epoch 35/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.6676 - accuracy: 0.3758 - val_loss: 3.6564 - val_accuracy: 0.3801\n",
      "Epoch 36/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.4942 - accuracy: 0.4025 - val_loss: 3.5083 - val_accuracy: 0.4067\n",
      "Epoch 37/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.5007 - accuracy: 0.4012 - val_loss: 3.5957 - val_accuracy: 0.3923\n",
      "Epoch 38/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.5019 - accuracy: 0.4008 - val_loss: 3.8602 - val_accuracy: 0.3540\n",
      "Epoch 39/130\n",
      "332/332 [==============================] - 129s 388ms/step - loss: 3.5304 - accuracy: 0.3981 - val_loss: 4.1875 - val_accuracy: 0.3109\n",
      "Epoch 40/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.5734 - accuracy: 0.3926 - val_loss: 3.4112 - val_accuracy: 0.4301\n",
      "Epoch 41/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.3589 - accuracy: 0.4360 - val_loss: 3.2281 - val_accuracy: 0.4525\n",
      "Epoch 42/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.1139 - accuracy: 0.4761 - val_loss: 3.2051 - val_accuracy: 0.4524\n",
      "Epoch 43/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.1386 - accuracy: 0.4614 - val_loss: 3.2032 - val_accuracy: 0.4584\n",
      "Epoch 44/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.1541 - accuracy: 0.4605 - val_loss: 3.0685 - val_accuracy: 0.4731\n",
      "Epoch 45/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.0192 - accuracy: 0.4789 - val_loss: 3.4532 - val_accuracy: 0.4175\n",
      "Epoch 46/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.0721 - accuracy: 0.4687 - val_loss: 3.3561 - val_accuracy: 0.4373\n",
      "Epoch 47/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.0288 - accuracy: 0.4836 - val_loss: 3.3665 - val_accuracy: 0.4425\n",
      "Epoch 48/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.2364 - accuracy: 0.4577 - val_loss: 3.2338 - val_accuracy: 0.4688\n",
      "Epoch 49/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.0829 - accuracy: 0.4869 - val_loss: 3.1717 - val_accuracy: 0.4744\n",
      "Epoch 50/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.0770 - accuracy: 0.4805 - val_loss: 3.2119 - val_accuracy: 0.4725\n",
      "Epoch 51/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.1000 - accuracy: 0.4855 - val_loss: 3.2374 - val_accuracy: 0.4715\n",
      "Epoch 52/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.0145 - accuracy: 0.5019 - val_loss: 3.2221 - val_accuracy: 0.4604\n",
      "Epoch 53/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.0502 - accuracy: 0.4905 - val_loss: 3.2434 - val_accuracy: 0.4589\n",
      "Epoch 54/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.0169 - accuracy: 0.5005 - val_loss: 4.2327 - val_accuracy: 0.3092\n",
      "Epoch 55/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.1067 - accuracy: 0.4837 - val_loss: 3.1016 - val_accuracy: 0.4985\n",
      "Epoch 56/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.0521 - accuracy: 0.4950 - val_loss: 3.4404 - val_accuracy: 0.4447\n",
      "Epoch 57/130\n",
      "332/332 [==============================] - 129s 388ms/step - loss: 3.0779 - accuracy: 0.4946 - val_loss: 3.3457 - val_accuracy: 0.4684\n",
      "Epoch 58/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.2090 - accuracy: 0.4863 - val_loss: 3.2624 - val_accuracy: 0.4779\n",
      "Epoch 59/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.0878 - accuracy: 0.5065 - val_loss: 3.7234 - val_accuracy: 0.4133\n",
      "Epoch 60/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.3710 - accuracy: 0.4760 - val_loss: 11.2051 - val_accuracy: 0.0181\n",
      "Epoch 61/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.6045 - accuracy: 0.4344 - val_loss: 3.3310 - val_accuracy: 0.4972\n",
      "Epoch 62/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 3.0917 - accuracy: 0.5342 - val_loss: 3.2101 - val_accuracy: 0.5124\n",
      "Epoch 63/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 2.9773 - accuracy: 0.5452 - val_loss: 3.0688 - val_accuracy: 0.5285\n",
      "Epoch 64/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 2.9195 - accuracy: 0.5493 - val_loss: 3.1431 - val_accuracy: 0.5208\n",
      "Epoch 65/130\n",
      "332/332 [==============================] - 129s 388ms/step - loss: 2.8531 - accuracy: 0.5539 - val_loss: 3.0656 - val_accuracy: 0.5208\n",
      "Epoch 66/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 2.8609 - accuracy: 0.5535 - val_loss: 2.9321 - val_accuracy: 0.5420\n",
      "Epoch 67/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 2.7974 - accuracy: 0.5638 - val_loss: 2.9581 - val_accuracy: 0.5377\n",
      "Epoch 68/130\n",
      "332/332 [==============================] - 129s 388ms/step - loss: 2.8277 - accuracy: 0.5517 - val_loss: 2.8978 - val_accuracy: 0.5441\n",
      "Epoch 69/130\n",
      "332/332 [==============================] - 129s 388ms/step - loss: 2.8162 - accuracy: 0.5534 - val_loss: 2.8442 - val_accuracy: 0.5531\n",
      "Epoch 70/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 2.6720 - accuracy: 0.5813 - val_loss: 2.8655 - val_accuracy: 0.5445\n",
      "Epoch 71/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 2.7239 - accuracy: 0.5600 - val_loss: 2.9668 - val_accuracy: 0.5269\n",
      "Epoch 72/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 2.6805 - accuracy: 0.5780 - val_loss: 2.8975 - val_accuracy: 0.5421\n",
      "Epoch 73/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 2.6707 - accuracy: 0.5737 - val_loss: 2.7831 - val_accuracy: 0.5563\n",
      "Epoch 74/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 2.6841 - accuracy: 0.5726 - val_loss: 2.7256 - val_accuracy: 0.5672\n",
      "Epoch 75/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 2.6121 - accuracy: 0.5863 - val_loss: 2.8912 - val_accuracy: 0.5415\n",
      "Epoch 76/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 2.5767 - accuracy: 0.5894 - val_loss: 2.8179 - val_accuracy: 0.5519\n",
      "Epoch 77/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 2.5543 - accuracy: 0.5928 - val_loss: 3.1068 - val_accuracy: 0.4996\n",
      "Epoch 78/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 2.7483 - accuracy: 0.5561 - val_loss: 2.9661 - val_accuracy: 0.5273\n",
      "Epoch 79/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 2.5825 - accuracy: 0.5943 - val_loss: 3.4105 - val_accuracy: 0.4417\n",
      "Epoch 80/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 2.8503 - accuracy: 0.5394 - val_loss: 2.8791 - val_accuracy: 0.5452\n",
      "Epoch 81/130\n",
      "332/332 [==============================] - 129s 388ms/step - loss: 2.5624 - accuracy: 0.5996 - val_loss: 2.6691 - val_accuracy: 0.5872\n",
      "Epoch 82/130\n",
      "332/332 [==============================] - 129s 388ms/step - loss: 2.4464 - accuracy: 0.6285 - val_loss: 2.7424 - val_accuracy: 0.5732\n",
      "Epoch 83/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 2.3826 - accuracy: 0.6357 - val_loss: 2.6489 - val_accuracy: 0.5880\n",
      "Epoch 84/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 2.3576 - accuracy: 0.6372 - val_loss: 2.6506 - val_accuracy: 0.5821\n",
      "Epoch 85/130\n",
      "332/332 [==============================] - 129s 390ms/step - loss: 2.3387 - accuracy: 0.6362 - val_loss: 2.7330 - val_accuracy: 0.5748\n",
      "Epoch 86/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 2.3114 - accuracy: 0.6422 - val_loss: 2.6218 - val_accuracy: 0.5928\n",
      "Epoch 87/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 2.2926 - accuracy: 0.6457 - val_loss: 2.6828 - val_accuracy: 0.5752\n",
      "Epoch 88/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 2.2607 - accuracy: 0.6493 - val_loss: 2.6131 - val_accuracy: 0.5879\n",
      "Epoch 89/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 2.2293 - accuracy: 0.6546 - val_loss: 2.6047 - val_accuracy: 0.5847\n",
      "Epoch 90/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 2.1972 - accuracy: 0.6581 - val_loss: 2.6755 - val_accuracy: 0.5764\n",
      "Epoch 91/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 2.1578 - accuracy: 0.6661 - val_loss: 2.8848 - val_accuracy: 0.5223\n",
      "Epoch 92/130\n",
      "332/332 [==============================] - 129s 390ms/step - loss: 2.3749 - accuracy: 0.6189 - val_loss: 2.7808 - val_accuracy: 0.5591\n",
      "Epoch 93/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 2.3024 - accuracy: 0.6391 - val_loss: 2.4555 - val_accuracy: 0.6152\n",
      "Epoch 94/130\n",
      "332/332 [==============================] - 129s 390ms/step - loss: 2.2099 - accuracy: 0.6573 - val_loss: 2.4983 - val_accuracy: 0.6083\n",
      "Epoch 95/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 2.1984 - accuracy: 0.6585 - val_loss: 2.4987 - val_accuracy: 0.5988\n",
      "Epoch 96/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 2.1607 - accuracy: 0.6644 - val_loss: 2.6207 - val_accuracy: 0.5831\n",
      "Epoch 97/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 2.3126 - accuracy: 0.6352 - val_loss: 2.6534 - val_accuracy: 0.5772\n",
      "Epoch 98/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 2.2888 - accuracy: 0.6423 - val_loss: 2.7276 - val_accuracy: 0.5671\n",
      "Epoch 99/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 2.2679 - accuracy: 0.6486 - val_loss: 2.5855 - val_accuracy: 0.5957\n",
      "Epoch 100/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 2.2611 - accuracy: 0.6565 - val_loss: 2.6570 - val_accuracy: 0.5784\n",
      "Epoch 101/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 2.2034 - accuracy: 0.6654 - val_loss: 2.5791 - val_accuracy: 0.6031\n",
      "Epoch 102/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 2.1194 - accuracy: 0.6842 - val_loss: 2.5812 - val_accuracy: 0.6044\n",
      "Epoch 103/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 2.0726 - accuracy: 0.6907 - val_loss: 2.5204 - val_accuracy: 0.6145\n",
      "Epoch 104/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 2.0260 - accuracy: 0.7008 - val_loss: 2.6576 - val_accuracy: 0.5949\n",
      "Epoch 105/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 2.0166 - accuracy: 0.7030 - val_loss: 2.4742 - val_accuracy: 0.6197\n",
      "Epoch 106/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 1.9689 - accuracy: 0.7118 - val_loss: 2.6148 - val_accuracy: 0.5989\n",
      "Epoch 107/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 2.0064 - accuracy: 0.7001 - val_loss: 2.5218 - val_accuracy: 0.6137\n",
      "Epoch 108/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 2.0700 - accuracy: 0.6833 - val_loss: 2.5860 - val_accuracy: 0.6012\n",
      "Epoch 109/130\n",
      "332/332 [==============================] - 129s 390ms/step - loss: 1.9623 - accuracy: 0.7068 - val_loss: 2.4997 - val_accuracy: 0.6116\n",
      "Epoch 110/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 1.9660 - accuracy: 0.7073 - val_loss: 2.5548 - val_accuracy: 0.5983\n",
      "Epoch 111/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 1.9846 - accuracy: 0.6996 - val_loss: 2.5196 - val_accuracy: 0.6029\n",
      "Epoch 112/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 1.9553 - accuracy: 0.7052 - val_loss: 2.5565 - val_accuracy: 0.6025\n",
      "Epoch 113/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 1.9215 - accuracy: 0.7101 - val_loss: 2.4430 - val_accuracy: 0.6221\n",
      "Epoch 114/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 1.8812 - accuracy: 0.7227 - val_loss: 2.6575 - val_accuracy: 0.5925\n",
      "Epoch 115/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 1.9692 - accuracy: 0.7051 - val_loss: 2.6803 - val_accuracy: 0.5912\n",
      "Epoch 116/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 1.8762 - accuracy: 0.7233 - val_loss: 2.4690 - val_accuracy: 0.6153\n",
      "Epoch 117/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 1.8604 - accuracy: 0.7288 - val_loss: 2.4845 - val_accuracy: 0.6083\n",
      "Epoch 118/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 1.9072 - accuracy: 0.7088 - val_loss: 2.4656 - val_accuracy: 0.6184\n",
      "Epoch 119/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 1.8790 - accuracy: 0.7176 - val_loss: 2.5617 - val_accuracy: 0.6073\n",
      "Epoch 120/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 1.8571 - accuracy: 0.7205 - val_loss: 2.7213 - val_accuracy: 0.5807\n",
      "Epoch 121/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 1.8352 - accuracy: 0.7302 - val_loss: 2.4455 - val_accuracy: 0.6196\n",
      "Epoch 122/130\n",
      "332/332 [==============================] - 129s 390ms/step - loss: 1.7655 - accuracy: 0.7438 - val_loss: 2.5331 - val_accuracy: 0.6105\n",
      "Epoch 123/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 1.7370 - accuracy: 0.7511 - val_loss: 2.4363 - val_accuracy: 0.6252\n",
      "Epoch 124/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 1.7428 - accuracy: 0.7479 - val_loss: 2.4242 - val_accuracy: 0.6289\n",
      "Epoch 125/130\n",
      "332/332 [==============================] - 129s 390ms/step - loss: 1.7216 - accuracy: 0.7536 - val_loss: 2.4308 - val_accuracy: 0.6279\n",
      "Epoch 126/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 1.7502 - accuracy: 0.7474 - val_loss: 2.4322 - val_accuracy: 0.6253\n",
      "Epoch 127/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 1.6921 - accuracy: 0.7595 - val_loss: 2.4588 - val_accuracy: 0.6220\n",
      "Epoch 128/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 1.6866 - accuracy: 0.7588 - val_loss: 2.4435 - val_accuracy: 0.6257\n",
      "Epoch 129/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 1.6561 - accuracy: 0.7648 - val_loss: 2.4627 - val_accuracy: 0.6200\n",
      "Epoch 130/130\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 1.6657 - accuracy: 0.7630 - val_loss: 2.4451 - val_accuracy: 0.6239\n"
     ]
    }
   ],
   "source": [
    "sgd = optimizers.SGD(lr=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])\n",
    "\n",
    "hist = model.fit(datagen.flow(x_train, y_train,\n",
    "                                 batch_size=batch_size),\n",
    "                    steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                    epochs=maxepoches,\n",
    "                    validation_data=(x_val, y_val),callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T19:34:11.977949Z",
     "iopub.status.busy": "2021-06-27T19:34:11.977631Z",
     "iopub.status.idle": "2021-06-27T19:34:12.007637Z",
     "shell.execute_reply": "2021-06-27T19:34:12.006882Z",
     "shell.execute_reply.started": "2021-06-27T19:34:11.977917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_52 (Conv2D)           (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_56 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_57 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_58 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_59 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_60 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_61 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_62 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_63 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_64 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_65 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_66 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_67 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_64 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_68 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_69 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               51300     \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 15,047,588\n",
      "Trainable params: 15,038,116\n",
      "Non-trainable params: 9,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T19:22:08.745597Z",
     "iopub.status.busy": "2021-06-27T19:22:08.745280Z",
     "iopub.status.idle": "2021-06-27T19:22:34.354018Z",
     "shell.execute_reply": "2021-06-27T19:22:34.353191Z",
     "shell.execute_reply.started": "2021-06-27T19:22:08.745568Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test = model.predict(x_test).argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T19:22:51.695020Z",
     "iopub.status.busy": "2021-06-27T19:22:51.694708Z",
     "iopub.status.idle": "2021-06-27T19:22:51.699929Z",
     "shell.execute_reply": "2021-06-27T19:22:51.699134Z",
     "shell.execute_reply.started": "2021-06-27T19:22:51.694989Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([90, 33, 55, ..., 51, 42, 70])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T19:22:54.861314Z",
     "iopub.status.busy": "2021-06-27T19:22:54.860992Z",
     "iopub.status.idle": "2021-06-27T19:22:55.130997Z",
     "shell.execute_reply": "2021-06-27T19:22:55.130199Z",
     "shell.execute_reply.started": "2021-06-27T19:22:54.861282Z"
    }
   },
   "outputs": [],
   "source": [
    "#Salvo las predicciones y genero el archivo csv según el formato pedido\n",
    "df = pd.DataFrame(y_test, columns=[\"label\"])\n",
    "df.index.name = \"Id\"\n",
    "df.to_csv(\"submission_vgg2.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "35d319f83ab08ecd497627408ea36f4ad0a0ef0ec31f33b5bf93fec9ccad80dc"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
